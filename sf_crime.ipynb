{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SF Crime Data Analysis with PySpark\n",
    "\n",
    "In this notebook we use PySpark to explore a dataset from the San Francisco Police Department.\n",
    "Dataset link: [https://data.sfgov.org/Public-Safety/sf-data/skgt-fej3/data](https://data.sfgov.org/Public-Safety/sf-data/skgt-fej3/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/20 06:55:16 WARN Utils: Your hostname, codespaces-8f4ab0 resolves to a loopback address: 127.0.0.1; using 10.0.1.250 instead (on interface eth0)\n",
      "25/02/20 06:55:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/20 06:55:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession started\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "print(pyspark.__version__)\n",
    "\n",
    "# Create a SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SF Crime Analysis\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "print('SparkSession started')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV data using an RDD\n",
    "from csv import reader\n",
    "\n",
    "# Read all lines from the CSV file\n",
    "crime_data_lines = sc.textFile('data/sf_crime.csv')\n",
    "\n",
    "# Convert each line to a list of strings (removing extra quotes)\n",
    "df_crimes = crime_data_lines.map(lambda line: [x.strip('\"') for x in next(reader([line]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header: ['IncidntNum', 'Category', 'Descript', 'DayOfWeek', 'Date', 'Time', 'PdDistrict', 'Resolution', 'Address', 'X', 'Y', 'Location', 'PdId']\n",
      "First two data rows: [['179005317', 'OTHER OFFENSES', 'FALSE PERSONATION TO RECEIVE MONEY OR PROPERTY', 'Tuesday', '07/11/2017', '14:32', 'SOUTHERN', 'NONE', '800 Block of BRYANT ST', '-122.40340479147905', '37.775420706711', '(37.775420706711, -122.40340479147905)', '17900531709029'], ['179005210', 'FORGERY/COUNTERFEITING', 'MANUFACTURE OR SALE OF COUNTERFEIT GOODS', 'Tuesday', '07/11/2017', '17:27', 'SOUTHERN', 'NONE', '800 Block of BRYANT ST', '-122.40340479147905', '37.775420706711', '(37.775420706711, -122.40340479147905)', '17900521009261']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Extract header and filter it out\n",
    "header = df_crimes.first()\n",
    "print(\"Header:\", header)\n",
    "crimes = df_crimes.filter(lambda x: x != header)\n",
    "print(\"First two data rows:\", crimes.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/20 06:55:32 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "# Convert the RDD of lists to an RDD of Rows\n",
    "from pyspark.sql import Row\n",
    "\n",
    "def list_to_row(keys, values):\n",
    "    row_dict = dict(zip(keys, values))\n",
    "    return Row(**row_dict)\n",
    "\n",
    "rdd_rows = crimes.map(lambda x: list_to_row(header, x))\n",
    "df = spark.createDataFrame(rdd_rows)\n",
    "print(\"DataFrame created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+---------+----------+-----+----------+--------------+--------------------+-------------------+------------------+--------------------+--------------+\n",
      "|IncidntNum|            Category|            Descript|DayOfWeek|      Date| Time|PdDistrict|    Resolution|             Address|                  X|                 Y|            Location|          PdId|\n",
      "+----------+--------------------+--------------------+---------+----------+-----+----------+--------------+--------------------+-------------------+------------------+--------------------+--------------+\n",
      "| 179005317|      OTHER OFFENSES|FALSE PERSONATION...|  Tuesday|07/11/2017|14:32|  SOUTHERN|          NONE|800 Block of BRYA...|-122.40340479147905|   37.775420706711|(37.775420706711,...|17900531709029|\n",
      "| 179005210|FORGERY/COUNTERFE...|MANUFACTURE OR SA...|  Tuesday|07/11/2017|17:27|  SOUTHERN|          NONE|800 Block of BRYA...|-122.40340479147905|   37.775420706711|(37.775420706711,...|17900521009261|\n",
      "| 179005210|      OTHER OFFENSES|FRAUDULENT GAME O...|  Tuesday|07/11/2017|17:27|  SOUTHERN|          NONE|800 Block of BRYA...|-122.40340479147905|   37.775420706711|(37.775420706711,...|17900521009024|\n",
      "| 179005191|      OTHER OFFENSES|FALSE PERSONATION...|  Tuesday|07/11/2017|14:15|  SOUTHERN|          NONE|800 Block of BRYA...|-122.40340479147905|   37.775420706711|(37.775420706711,...|17900519109029|\n",
      "| 179004375|      OTHER OFFENSES|DRIVERS LICENSE, ...|  Tuesday|07/11/2017|22:57|  SOUTHERN|ARREST, BOOKED|800 Block of BRYA...|-122.40340479147905|   37.775420706711|(37.775420706711,...|17900437565016|\n",
      "| 179004375|      OTHER OFFENSES|TRAFFIC VIOLATION...|  Tuesday|07/11/2017|22:57|  SOUTHERN|ARREST, BOOKED|800 Block of BRYA...|-122.40340479147905|   37.775420706711|(37.775420706711,...|17900437565010|\n",
      "| 179004369|      OTHER OFFENSES|DRIVERS LICENSE, ...|  Tuesday|07/11/2017|18:36|   TARAVAL|ARREST, BOOKED|BUCKINGHAM WY / W...|-122.47869790186236| 37.72820962539442|(37.7282096253944...|17900436965016|\n",
      "| 176317688|        NON-CRIMINAL|       LOST PROPERTY|  Tuesday|07/11/2017|17:00|  SOUTHERN|          NONE|    4TH ST / KING ST|-122.39410262452486|  37.7763827130285|(37.7763827130285...|17631768871000|\n",
      "| 176224481|       LARCENY/THEFT|GRAND THEFT FROM ...|  Tuesday|07/11/2017|18:00|   CENTRAL|          NONE|TAYLOR ST / FILBE...|-122.41430481787901|37.800759320976745|(37.8007593209767...|17622448106244|\n",
      "| 176219448|       LARCENY/THEFT|PETTY THEFT OF PR...|  Tuesday|07/11/2017|19:21|  SOUTHERN|          NONE|  BRYANT ST / 3RD ST|-122.39584829915415|  37.7813210474369|(37.7813210474369...|17621944806372|\n",
      "| 176206871|       LARCENY/THEFT|GRAND THEFT FROM ...|  Tuesday|07/11/2017|21:00| INGLESIDE|          NONE|500 Block of BOWD...|-122.41181327592504|37.728801412109796|(37.7288014121097...|17620687106244|\n",
      "| 176206865|       LARCENY/THEFT|GRAND THEFT FROM ...|  Tuesday|07/11/2017|18:00|   BAYVIEW|          NONE|    3RD ST / 18TH ST|-122.38874206628272|37.763050111892504|(37.7630501118925...|17620686506244|\n",
      "| 176206859|        NON-CRIMINAL|       LOST PROPERTY|  Tuesday|07/11/2017|17:00|   BAYVIEW|          NONE|SAN BRUNO AV / SI...|-122.40561026822242|37.732438864981965|(37.7324388649819...|17620685971000|\n",
      "| 176198870|           VANDALISM|MALICIOUS MISCHIE...|  Tuesday|07/11/2017|10:39|      PARK|          NONE| 16TH ST / CASTRO ST|-122.43531842332727|  37.7641020287178|(37.7641020287178...|17619887028150|\n",
      "| 176197822|       LARCENY/THEFT|GRAND THEFT OF PR...|  Tuesday|07/11/2017|18:07|  SOUTHERN|          NONE|800 Block of BRYA...|-122.40340479147905|   37.775420706711|(37.775420706711,...|17619782206374|\n",
      "| 176193977|       LARCENY/THEFT|GRAND THEFT FROM ...|  Tuesday|07/11/2017|10:00|  RICHMOND|          NONE|2600 Block of CAL...| -122.4379780082345|37.788435356124936|(37.7884353561249...|17619397706244|\n",
      "| 176193682|       LARCENY/THEFT|PETTY THEFT OF PR...|  Tuesday|07/11/2017|16:00|  NORTHERN|          NONE|800 Block of FELL ST|-122.43183473706995| 37.77474151079809|(37.7747415107980...|17619368206372|\n",
      "| 176193262|       LARCENY/THEFT|GRAND THEFT OF PR...|  Tuesday|07/11/2017|11:00|  SOUTHERN|          NONE|800 Block of BRYA...|-122.40340479147905|   37.775420706711|(37.775420706711,...|17619326206374|\n",
      "| 176189346|        NON-CRIMINAL|       LOST PROPERTY|  Tuesday|07/11/2017|10:14|   TARAVAL|          NONE|2600 Block of 17T...|-122.47329461295605| 37.73846351019913|(37.7384635101991...|17618934671000|\n",
      "| 176188718|       LARCENY/THEFT|GRAND THEFT FROM ...|  Tuesday|07/11/2017|11:05|   CENTRAL|          NONE|0 Block of BROADW...|-122.39929569079513| 37.79885919839204|(37.7988591983920...|17618871806244|\n",
      "+----------+--------------------+--------------------+---------+----------+-----+----------+--------------+--------------------+-------------------+------------------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the DataFrame (first 20 rows)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns renamed and cast\n"
     ]
    }
   ],
   "source": [
    "# Replace columns 'X' and 'Y' with 'Longitude' and 'Latitude' and cast them as float\n",
    "df = df.withColumn('X', df['X'].cast('float')).withColumn('Y', df['Y'].cast('float'))\n",
    "df = df.withColumnRenamed('X', 'Longitude').withColumnRenamed('Y', 'Latitude')\n",
    "print(\"Columns renamed and cast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- IncidntNum: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Descript: string (nullable = true)\n",
      " |-- DayOfWeek: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- PdDistrict: string (nullable = true)\n",
      " |-- Resolution: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- Longitude: float (nullable = true)\n",
      " |-- Latitude: float (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- PdId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect the schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Data\n",
    "\n",
    "Let's count the number of incidents for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+-----+\n",
      "|Category                   |Count|\n",
      "+---------------------------+-----+\n",
      "|LARCENY/THEFT              |2804 |\n",
      "|OTHER OFFENSES             |1002 |\n",
      "|NON-CRIMINAL               |988  |\n",
      "|ASSAULT                    |780  |\n",
      "|VANDALISM                  |650  |\n",
      "|VEHICLE THEFT              |353  |\n",
      "|SUSPICIOUS OCC             |311  |\n",
      "|WARRANTS                   |309  |\n",
      "|BURGLARY                   |300  |\n",
      "|MISSING PERSON             |263  |\n",
      "|ROBBERY                    |187  |\n",
      "|DRUG/NARCOTIC              |167  |\n",
      "|FRAUD                      |155  |\n",
      "|SECONDARY CODES            |118  |\n",
      "|TRESPASS                   |109  |\n",
      "|WEAPON LAWS                |106  |\n",
      "|STOLEN PROPERTY            |66   |\n",
      "|RECOVERED VEHICLE          |48   |\n",
      "|SEX OFFENSES, FORCIBLE     |39   |\n",
      "|RUNAWAY                    |39   |\n",
      "|ARSON                      |29   |\n",
      "|FORGERY/COUNTERFEITING     |29   |\n",
      "|PROSTITUTION               |20   |\n",
      "|DRUNKENNESS                |19   |\n",
      "|DISORDERLY CONDUCT         |18   |\n",
      "|DRIVING UNDER THE INFLUENCE|16   |\n",
      "|KIDNAPPING                 |10   |\n",
      "|BRIBERY                    |7    |\n",
      "|EMBEZZLEMENT               |5    |\n",
      "|LIQUOR LAWS                |4    |\n",
      "|LOITERING                  |4    |\n",
      "|SUICIDE                    |3    |\n",
      "|EXTORTION                  |2    |\n",
      "|FAMILY OFFENSES            |1    |\n",
      "|PORNOGRAPHY/OBSCENE MAT    |1    |\n",
      "|SEX OFFENSES, NON FORCIBLE |1    |\n",
      "|TREA                       |1    |\n",
      "+---------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Using Spark SQL\n",
    "df.createOrReplaceTempView(\"crime\")\n",
    "sqlDF = spark.sql(\"\"\"\n",
    "    SELECT Category, COUNT(*) AS Count \n",
    "    FROM crime \n",
    "    GROUP BY Category \n",
    "    ORDER BY Count DESC\n",
    "\"\"\")\n",
    "sqlDF.show(40, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+-----+\n",
      "|Category                   |count|\n",
      "+---------------------------+-----+\n",
      "|LARCENY/THEFT              |2804 |\n",
      "|OTHER OFFENSES             |1002 |\n",
      "|NON-CRIMINAL               |988  |\n",
      "|ASSAULT                    |780  |\n",
      "|VANDALISM                  |650  |\n",
      "|VEHICLE THEFT              |353  |\n",
      "|SUSPICIOUS OCC             |311  |\n",
      "|WARRANTS                   |309  |\n",
      "|BURGLARY                   |300  |\n",
      "|MISSING PERSON             |263  |\n",
      "|ROBBERY                    |187  |\n",
      "|DRUG/NARCOTIC              |167  |\n",
      "|FRAUD                      |155  |\n",
      "|SECONDARY CODES            |118  |\n",
      "|TRESPASS                   |109  |\n",
      "|WEAPON LAWS                |106  |\n",
      "|STOLEN PROPERTY            |66   |\n",
      "|RECOVERED VEHICLE          |48   |\n",
      "|SEX OFFENSES, FORCIBLE     |39   |\n",
      "|RUNAWAY                    |39   |\n",
      "|ARSON                      |29   |\n",
      "|FORGERY/COUNTERFEITING     |29   |\n",
      "|PROSTITUTION               |20   |\n",
      "|DRUNKENNESS                |19   |\n",
      "|DISORDERLY CONDUCT         |18   |\n",
      "|DRIVING UNDER THE INFLUENCE|16   |\n",
      "|KIDNAPPING                 |10   |\n",
      "|BRIBERY                    |7    |\n",
      "|EMBEZZLEMENT               |5    |\n",
      "|LIQUOR LAWS                |4    |\n",
      "|LOITERING                  |4    |\n",
      "|SUICIDE                    |3    |\n",
      "|EXTORTION                  |2    |\n",
      "|FAMILY OFFENSES            |1    |\n",
      "|PORNOGRAPHY/OBSCENE MAT    |1    |\n",
      "|SEX OFFENSES, NON FORCIBLE |1    |\n",
      "|TREA                       |1    |\n",
      "+---------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Using DataFrame functions\n",
    "df.groupBy(\"Category\").count().orderBy(\"count\", ascending=False).show(40, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('LARCENY/THEFT', 2804), ('OTHER OFFENSES', 1002), ('NON-CRIMINAL', 988), ('ASSAULT', 780), ('VANDALISM', 650), ('VEHICLE THEFT', 353), ('SUSPICIOUS OCC', 311), ('WARRANTS', 309), ('BURGLARY', 300), ('MISSING PERSON', 263), ('ROBBERY', 187), ('DRUG/NARCOTIC', 167), ('FRAUD', 155), ('SECONDARY CODES', 118), ('TRESPASS', 109), ('WEAPON LAWS', 106), ('STOLEN PROPERTY', 66), ('RECOVERED VEHICLE', 48), ('SEX OFFENSES, FORCIBLE', 39), ('RUNAWAY', 39), ('FORGERY/COUNTERFEITING', 29), ('ARSON', 29), ('PROSTITUTION', 20), ('DRUNKENNESS', 19), ('DISORDERLY CONDUCT', 18), ('DRIVING UNDER THE INFLUENCE', 16), ('KIDNAPPING', 10), ('BRIBERY', 7), ('EMBEZZLEMENT', 5), ('LOITERING', 4), ('LIQUOR LAWS', 4), ('SUICIDE', 3), ('EXTORTION', 2), ('PORNOGRAPHY/OBSCENE MAT', 1), ('SEX OFFENSES, NON FORCIBLE', 1), ('FAMILY OFFENSES', 1), ('TREA', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Method 3: Using RDD functions\n",
    "rdd = crimes.map(lambda line: (line[1], 1))\n",
    "sorted_counts = sorted(rdd.countByKey().items(), key=lambda x: -x[1])\n",
    "print(sorted_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about the number of incidents at each district?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|PdDistrict|Count|\n",
      "+----------+-----+\n",
      "|  SOUTHERN| 1743|\n",
      "|   MISSION| 1190|\n",
      "|  NORTHERN| 1169|\n",
      "|   CENTRAL| 1137|\n",
      "|   BAYVIEW|  816|\n",
      "| INGLESIDE|  670|\n",
      "|   TARAVAL|  660|\n",
      "|TENDERLOIN|  535|\n",
      "|  RICHMOND|  527|\n",
      "|      PARK|  517|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Method 1: SQL\n",
    "sqlDF = spark.sql(\"\"\"\n",
    "    SELECT PdDistrict, COUNT(*) AS Count \n",
    "    FROM crime \n",
    "    GROUP BY PdDistrict \n",
    "    ORDER BY Count DESC\n",
    "\"\"\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|PdDistrict|count|\n",
      "+----------+-----+\n",
      "|  SOUTHERN| 1743|\n",
      "|   MISSION| 1190|\n",
      "|  NORTHERN| 1169|\n",
      "|   CENTRAL| 1137|\n",
      "|   BAYVIEW|  816|\n",
      "| INGLESIDE|  670|\n",
      "|   TARAVAL|  660|\n",
      "|TENDERLOIN|  535|\n",
      "|  RICHMOND|  527|\n",
      "|      PARK|  517|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Method 2: DataFrame\n",
    "df.groupBy(\"PdDistrict\").count().orderBy(\"count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SOUTHERN', 1743), ('MISSION', 1190), ('NORTHERN', 1169), ('CENTRAL', 1137), ('BAYVIEW', 816), ('INGLESIDE', 670), ('TARAVAL', 660), ('TENDERLOIN', 535), ('RICHMOND', 527), ('PARK', 517)]\n"
     ]
    }
   ],
   "source": [
    "# Method 3: RDD functions\n",
    "rdd_district = crimes.map(lambda line: (line[6], 1))\n",
    "sorted_district_counts = sorted(rdd_district.countByKey().items(), key=lambda x: -x[1])\n",
    "print(sorted_district_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define \"downtown\" as an area within 0.005 degrees from (37.792489, -122.403221). \n",
    "Let's count the number of incidents on Sundays within this area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----+\n",
      "|      Date|DayOfWeek|Count|\n",
      "+----------+---------+-----+\n",
      "|07/16/2017|   Sunday|   10|\n",
      "|07/23/2017|   Sunday|   20|\n",
      "|07/30/2017|   Sunday|   14|\n",
      "+----------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Method 1: SQL\n",
    "sqlDF = spark.sql(\"\"\"\n",
    "    SELECT Date, DayOfWeek, COUNT(*) AS Count \n",
    "    FROM crime \n",
    "    WHERE DayOfWeek = 'Sunday'\n",
    "      AND POW(Latitude - 37.792489, 2) + POW(Longitude + 122.403221, 2) < POW(0.005, 2)\n",
    "    GROUP BY Date, DayOfWeek \n",
    "    ORDER BY Date\n",
    "\"\"\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----+\n",
      "|      Date|DayOfWeek|count|\n",
      "+----------+---------+-----+\n",
      "|07/16/2017|   Sunday|   10|\n",
      "|07/23/2017|   Sunday|   20|\n",
      "|07/30/2017|   Sunday|   14|\n",
      "+----------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Method 2: DataFrame\n",
    "df_downtown = df.filter((df['Latitude'] - 37.792489)**2 + (df['Longitude'] + 122.403221)**2 < 0.005**2)\n",
    "df_downtown.filter(df_downtown['DayOfWeek'] == 'Sunday') \\\n",
    "    .groupBy(\"Date\", \"DayOfWeek\") \\\n",
    "    .count() \\\n",
    "    .orderBy('Date') \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Spatial Distribution\n",
    "\n",
    "Let's make a scatter plot of the crimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==2.1.0\n",
      "  Downloading pandas-2.1.0.tar.gz (4.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l|"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pandas==2.1.0 seaborn==0.12.2 matplotlib==3.8.0\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert the Spark DataFrame to Pandas for plotting\n",
    "pdf = df.select(\"Longitude\", \"Latitude\").toPandas()\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('SF Crime Distribution')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.scatter(pdf['Longitude'], pdf['Latitude'], s=2, c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering with Spark ML\n",
    "\n",
    "Spark ML requires that features be in a single vector column. We'll use the `VectorAssembler` to\n",
    "combine the `Longitude` and `Latitude` columns into one features column, and then fit a k-means\n",
    "model (with k=3, chosen arbitrarily)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "df_coor = df.select(\"Longitude\", \"Latitude\")\n",
    "vecAssembler = VectorAssembler(inputCols=[\"Longitude\", \"Latitude\"], outputCol=\"features\")\n",
    "new_df = vecAssembler.transform(df_coor).select(\"features\")\n",
    "new_df.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a k-means model with k=3 and a fixed seed for reproducibility\n",
    "kmeans = KMeans().setK(3).setSeed(1)\n",
    "model = kmeans.fit(new_df)\n",
    "\n",
    "# Print cluster centers\n",
    "centers = model.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)\n",
    "\n",
    "# Show cluster memberships\n",
    "transformed = model.transform(new_df)\n",
    "transformed.show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Clustering Results\n",
    "\n",
    "You can now visualize the clusters (for example, by converting the predictions back to Pandas\n",
    "and plotting them with different colors). Below is one example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_clusters = transformed.select(\"features\", \"prediction\").toPandas()\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('KMeans Clustering of SF Crimes')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.scatter(pdf_clusters['features'].apply(lambda x: x[0]),\n",
    "            pdf_clusters['features'].apply(lambda x: x[1]),\n",
    "            c=pdf_clusters['prediction'], cmap='viridis', s=2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
